{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb51609a",
   "metadata": {},
   "source": [
    "<h2> Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f6b611d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "import math\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92cee7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedder(nn.Module): #임베딩 레이어\n",
    "    def __init__(self,vocab_size,d_model):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size,d_model)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        #x= x.to(\"cpu\")\n",
    "        return self.embed(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "764751d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = Embedder(32000,768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ba3257d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.9001, -0.8623,  0.2188,  ..., -0.3597, -0.2111,  0.7606],\n",
       "        [-0.5931, -0.4646, -0.9410,  ...,  1.1490,  2.8431,  0.7688],\n",
       "        [-0.7765,  0.2146,  0.5302,  ...,  0.9150,  0.1083, -0.6795]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = torch.tensor([1,2,3])\n",
    "e(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42b69a9",
   "metadata": {},
   "source": [
    "<h2> Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14ba0a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoder(nn.Module): #위치 인코딩 레이어\n",
    "    def __init__(self, d_model, max_seq_len = 128):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        #위치 인코딩 초기화\n",
    "        positional_encoding = torch.zeros(max_seq_len, d_model)\n",
    "        \n",
    "        for pos in range(max_seq_len):\n",
    "            for i in range(0, d_model, 2):\n",
    "                positional_encoding[pos, i] = math.sin(pos / (10000 ** ((2 * i)/d_model)))\n",
    "                positional_encoding[pos, i + 1] = math.cos(pos / (10000 ** ((2 * (i + 1))/d_model)))\n",
    "                \n",
    "        positional_encoding = positional_encoding.unsqueeze(0)\n",
    "        #잔차 연결\n",
    "        self.register_buffer('positional_encoding', positional_encoding)\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = x * math.sqrt(self.d_model)\n",
    "        seq_len = x.size(1)\n",
    "        x = x + self.positional_encoding[:,:seq_len]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "361f9984",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = PositionalEncoder(768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "229e31cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 768])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y_pred값 대충 생성\n",
    "input_seq = torch.randint(0,40,(128,))\n",
    "emb = e(input_seq)\n",
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c0c8758",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = p(emb.to(\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "73072b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y값 대충 생성\n",
    "input_seq2 = torch.randint(0,40,(128,))\n",
    "emb2 = e(input_seq2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "66ec263b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = p(emb2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5693904c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.mean((y_pred - y)**2)\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bc27cb",
   "metadata": {},
   "source": [
    "<h2> Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6d7d1c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attn_mask(input_seq,input_pad):\n",
    "    return (input_seq != input_pad).unsqueeze(1).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "251c0c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_attn_mask(target_seq,target_pad):\n",
    "    target_mask = (target_seq != target_pad).unsqueeze(1)\n",
    "    size = target_seq.size(1)\n",
    "    nopeak_mask = np.triu(np.ones((1,size,size)),k=1).astype('uint8')\n",
    "    nopeak_mask = torch.from_numpy(nopeak_mask) == 0\n",
    "    nopeak_mask = nopeak_mask.to(\"cuda\")\n",
    "    target_mask = target_mask & nopeak_mask\n",
    "    return target_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9f5650",
   "metadata": {},
   "source": [
    "<h2> Self-Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f08775d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b100bf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention(query, key, value, d_k, attention_mask=False, dropout=None):\n",
    "    \n",
    "    scores = torch.matmul(query,key.transpose(-2,-1)) /  math.sqrt(d_k)\n",
    "    \n",
    "    if attention_mask is True:\n",
    "        attention_mask = get_attn_mask(scores,0)\n",
    "        attention_mask = attention_mask.unsqueeze(1)\n",
    "        scores = scores.masked_fill(attention_mask == 0, -1e9)\n",
    "    \n",
    "    scores = F.softmax(scores, dim=-1)\n",
    "    \n",
    "    if dropout is not None:\n",
    "        scores = dropout(scores)\n",
    "        \n",
    "    output = torch.matmul(scores, value)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318955dc",
   "metadata": {},
   "source": [
    "<h2> Multi-Headed Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "72e10e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "20fe1122",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self,heads,d_model,dropout_rate = 0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.d_k = d_model // heads\n",
    "        self.h = heads\n",
    "        \n",
    "        self.query_layer = nn.Linear(d_model,d_model)\n",
    "        self.key_layer = nn.Linear(d_model,d_model)\n",
    "        self.value_layer = nn.Linear(d_model,d_model)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.out_layer = nn.Linear(d_model,d_model)\n",
    "        \n",
    "    def forward(self,query,key,value,attention_mask = True):\n",
    "        \n",
    "        batch_size = query.size(0)\n",
    "        \n",
    "        query = self.key_layer(query).view(batch_size,-1,self.h,self.d_k)\n",
    "        key = self.key_layer(key).view(batch_size,-1,self.h,self.d_k)\n",
    "        value = self.key_layer(value).view(batch_size,-1,self.h,self.d_k)\n",
    "        \n",
    "        query =  query.transpose(1,2)\n",
    "        key = key.transpose(1,2)\n",
    "        value = value.transpose(1,2)\n",
    "        \n",
    "        scores = attention(query,key,value,self.d_k,attention_mask,self.dropout)\n",
    "        Z = scores.transpose(1,2).contiguous().view(batch_size,-1,self.d_model)\n",
    "        output = self.dropout(Z)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cd8dd240",
   "metadata": {},
   "outputs": [],
   "source": [
    "mha = MultiHeadAttention(8,512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c769adcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = torch.rand((1,3,512))\n",
    "key = torch.rand((1,3,512))\n",
    "value = torch.rand((1,3,512))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07160d0e",
   "metadata": {},
   "source": [
    "<h2> Feed-Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f2739259",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self,d_model,d_ff = 2048,dropout = 0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(d_model,d_ff)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(d_ff,d_model)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127591b0",
   "metadata": {},
   "source": [
    "<h2> Normalisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fdeb25",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>prevents the range of value in the layers changing too much\n",
    "<li>it makes model trains faster and has better ability</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "51067e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Norm(nn.Module):\n",
    "    def __init__(self,d_model,eps = 1e-6):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.size = d_model\n",
    "        \n",
    "        self.alpha = nn.Parameter(torch.ones(self.size))\n",
    "        self.bias = nn.Parameter(torch.zeros(self.size))\n",
    "        self.eps = eps\n",
    "    \n",
    "    def forward(self,x):\n",
    "        norm = self.alpha *(x - x.mean(dim = -1,keepdim=True)) / (x.std(dim=-1, keepdim=True) + self.eps) + self.bias\n",
    "        return norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8dab34",
   "metadata": {},
   "source": [
    "<h1> ★Encoder&Decoder Layer★"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed717f39",
   "metadata": {},
   "source": [
    "<ui>\n",
    "<li> build an encoder layer with one multi-head attention layer and one feed-forward layer </li>\n",
    "</ui>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c831f6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self,d_model,heads,dropout = 0.1):\n",
    "        super().__init__()\n",
    "        self.norm1 = Norm(d_model)\n",
    "        self.norm2 = Norm(d_model)\n",
    "        self.mha = MultiHeadAttention(heads,d_model)\n",
    "        self.ff = FeedForward(d_model)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self,x,mask):\n",
    "        x2 = self.norm1(x)\n",
    "        x = x + self.dropout1(self.mha(x2,x2,x2,mask))\n",
    "        x2 = self.norm2(x)\n",
    "        x = x + self.dropout2(self.ff(x2))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "de23f8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self,d_model,heads,dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.norm1 = Norm(d_model)\n",
    "        self.norm2 = Norm(d_model)\n",
    "        self.norm3 = Norm(d_model)\n",
    "        \n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.dropout3 = nn.Dropout(dropout)\n",
    "        \n",
    "        self.mha1 = MultiHeadAttention(heads, d_model)\n",
    "        self.mha2 = MultiHeadAttention(heads, d_model)\n",
    "        self.ff = FeedForward(d_model)\n",
    "        \n",
    "    def forward(self,x,encoder_outputs,src_mask,trg_mask):\n",
    "        x2 = self.norm1(x)\n",
    "        x = x + self.dropout1(self.mha1(x2,x2,x2,trg_mask))\n",
    "        \n",
    "        x2 = self.norm2(x)\n",
    "        x = x + self.dropout2(self.mha2(x2,encoder_outputs,encoder_outputs,src_mask))\n",
    "        \n",
    "        x2 = self.norm3(x)\n",
    "        x = x + self.dropout3(self.ff(x2))\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2edbc29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a conveinient cloning function that can generate multiple layers\n",
    "import copy\n",
    "def get_clones(module,N):\n",
    "    return nn.ModuleList([copy.deepcopy(module) for i in range(N)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997feb4b",
   "metadata": {},
   "source": [
    "<h1> Encoder Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "45796bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self,vocab_size,d_model,N,heads):\n",
    "        super().__init__()\n",
    "        self.N = N\n",
    "        self.embed = Embedder(vocab_size,d_model)\n",
    "        self.pe = PositionalEncoder(d_model)\n",
    "        self.layers = get_clones(EncoderLayer(d_model,heads),N)\n",
    "        self.norm = Norm(d_model)\n",
    "    \n",
    "    def forward(self,src,mask):\n",
    "        x = self.embed(src)\n",
    "        x = self.pe(x)\n",
    "        for i in range(self.N):\n",
    "            x = self.layers[i](x,mask)\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0ae1079c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self,vocab_size,d_model,N,heads):\n",
    "        super().__init__()\n",
    "        self.N = N\n",
    "        self.embed = Embedder(vocab_size,d_model)\n",
    "        self.pe = PositionalEncoder(d_model)\n",
    "        self.layers = get_clones(DecoderLayer(d_model,heads),N)\n",
    "        self.norm = Norm(d_model)\n",
    "    def forward(self,target,encoder_outputs,src_mask,target_mask):\n",
    "        x = self.embed(target)\n",
    "        x = self.pe(x)\n",
    "        for i in range(self.N):\n",
    "            x = self.layers[i](x,encoder_outputs,src_mask,target_mask)\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f651336b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, src_vocab, trg_vocab, d_model, N, heads):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(src_vocab, d_model, N, heads)\n",
    "        self.decoder = Decoder(trg_vocab, d_model, N, heads)\n",
    "        self.out = nn.Linear(d_model, trg_vocab)\n",
    "    def forward(self, src, trg, src_mask, trg_mask):\n",
    "        e_outputs = self.encoder(src, src_mask)\n",
    "        d_output = self.decoder(trg, e_outputs, src_mask, trg_mask)\n",
    "        output = self.out(d_output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4caf29f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset,DataLoader\n",
    "import time\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d5ec5b",
   "metadata": {},
   "source": [
    "<h2> Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e91f75c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NMTDataset(Dataset):\n",
    "    def __init__(self, text_df, vectorizer):\n",
    "        \n",
    "        self.text_df = text_df\n",
    "        self._vectorizer = vectorizer\n",
    "\n",
    "        self.train_df = self.text_df[self.text_df.split=='train']\n",
    "        self.train_size = len(self.train_df)\n",
    "\n",
    "        self.val_df = self.text_df[self.text_df.split=='val']\n",
    "        self.validation_size = len(self.val_df)\n",
    "\n",
    "        self.test_df = self.text_df[self.text_df.split=='test']\n",
    "        self.test_size = len(self.test_df)\n",
    "\n",
    "        self._lookup_dict = {'train': (self.train_df, self.train_size),\n",
    "                             'val': (self.val_df, self.validation_size),\n",
    "                             'test': (self.test_df, self.test_size)}\n",
    "\n",
    "        self.set_split('train')\n",
    "\n",
    "    @classmethod\n",
    "    def load_dataset_and_make_vectorizer(cls, dataset_csv):\n",
    "        text_df = pd.read_csv(dataset_csv)\n",
    "        train_subset = text_df[text_df.split=='train']\n",
    "        return cls(text_df, NMTVectorizer.from_dataframe(train_subset))\n",
    "\n",
    "    @classmethod\n",
    "    def load_dataset_and_load_vectorizer(cls, dataset_csv, vectorizer_filepath):\n",
    "        text_df = pd.read_csv(dataset_csv)\n",
    "        vectorizer = cls.load_vectorizer_only(vectorizer_filepath)\n",
    "        return cls(text_df, vectorizer)\n",
    "\n",
    "    @staticmethod\n",
    "    def load_vectorizer_only(vectorizer_filepath):\n",
    "        with open(vectorizer_filepath) as fp:\n",
    "            return NMTVectorizer.from_serializable(json.load(fp))\n",
    "\n",
    "    def save_vectorizer(self, vectorizer_filepath):\n",
    "        with open(vectorizer_filepath, \"w\") as fp:\n",
    "            json.dump(self._vectorizer.to_serializable(), fp)\n",
    "\n",
    "    def get_vectorizer(self):\n",
    "        return self._vectorizer\n",
    "\n",
    "    def set_split(self, split=\"train\"):\n",
    "        self._target_split = split\n",
    "        self._target_df, self._target_size = self._lookup_dict[split]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._target_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        row = self._target_df.iloc[index]\n",
    "\n",
    "        vector_dict = self._vectorizer.vectorize(row.source_language, row.target_language)\n",
    "\n",
    "        return {\"source\": vector_dict[\"source_vector\"], \n",
    "                \"target\": vector_dict[\"target_vector\"],\n",
    "                \"source_length\": vector_dict[\"source_length\"]}\n",
    "        \n",
    "    def get_num_batches(self, batch_size):\n",
    "\n",
    "        return len(self) // batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaadb2f1",
   "metadata": {},
   "source": [
    "<h2> DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "821dbada",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "def generate_nmt_batches(dataset, batch_size, shuffle=True, \n",
    "                            drop_last=True, device=\"cuda\"):\n",
    "\n",
    "    dataloader = DataLoader(dataset=dataset, batch_size=batch_size,\n",
    "                            shuffle=shuffle, drop_last=drop_last)\n",
    "\n",
    "    for data_dict in dataloader:\n",
    "        print(type(data_dict))\n",
    "        lengths = data_dict['source_length'].numpy()\n",
    "        sorted_length_indices = lengths.argsort().tolist()\n",
    "        out_data_dict = {}\n",
    "        for name, tensor in data_dict.items():\n",
    "            out_data_dict[name] = data_dict[name][sorted_length_indices].to(device)\n",
    "        yield out_data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0b9498",
   "metadata": {},
   "source": [
    "<h2> Vocabulary\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "29cd9754",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary(object):\n",
    "    def __init__(self, token_to_idx=None):\n",
    "\n",
    "        if token_to_idx is None:\n",
    "            token_to_idx = {}\n",
    "            \n",
    "        self._token_to_idx = token_to_idx\n",
    "\n",
    "        self._idx_to_token = {idx: token \n",
    "                              for token, idx in self._token_to_idx.items()}\n",
    "        \n",
    "    def to_serializable(self):\n",
    "        return {'token_to_idx': self._token_to_idx}\n",
    "\n",
    "    @classmethod\n",
    "    def from_serializable(cls, contents):\n",
    "        return cls(**contents)\n",
    "\n",
    "    def add_token(self, token):\n",
    "        if token in self._token_to_idx:\n",
    "            index = self._token_to_idx[token]\n",
    "        else:\n",
    "            index = len(self._token_to_idx)\n",
    "            self._token_to_idx[token] = index\n",
    "            self._idx_to_token[index] = token\n",
    "        return index\n",
    "            \n",
    "    def add_many(self, tokens):\n",
    "        return [self.add_token(token) for token in tokens]\n",
    "\n",
    "    def lookup_token(self, token):\n",
    "        return self._token_to_idx[token]\n",
    "\n",
    "    def lookup_index(self, index):\n",
    "        if index not in self._idx_to_token:\n",
    "            raise KeyError(\"the index (%d) is not in the Vocabulary\" % index)\n",
    "        return self._idx_to_token[index]\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"<Vocabulary(size=%d)>\" % len(self)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._token_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6d042028",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceVocabulary(Vocabulary):\n",
    "    def __init__(self, token_to_idx=None, unk_token=\"<UNK>\",\n",
    "                 mask_token=\"<MASK>\", begin_seq_token=\"<BEGIN>\",\n",
    "                 end_seq_token=\"<END>\"):\n",
    "\n",
    "        super(SequenceVocabulary, self).__init__(token_to_idx)\n",
    "\n",
    "        self._mask_token = mask_token\n",
    "        self._unk_token = unk_token\n",
    "        self._begin_seq_token = begin_seq_token\n",
    "        self._end_seq_token = end_seq_token\n",
    "\n",
    "        self.mask_index = self.add_token(self._mask_token)\n",
    "        self.unk_index = self.add_token(self._unk_token)\n",
    "        self.begin_seq_index = self.add_token(self._begin_seq_token)\n",
    "        self.end_seq_index = self.add_token(self._end_seq_token)\n",
    "\n",
    "    def to_serializable(self):\n",
    "        contents = super(SequenceVocabulary, self).to_serializable()\n",
    "        contents.update({'unk_token': self._unk_token,\n",
    "                         'mask_token': self._mask_token,\n",
    "                         'begin_seq_token': self._begin_seq_token,\n",
    "                         'end_seq_token': self._end_seq_token})\n",
    "        return contents\n",
    "\n",
    "    def lookup_token(self, token):\n",
    "        if self.unk_index >= 0:\n",
    "            return self._token_to_idx.get(token, self.unk_index)\n",
    "        else:\n",
    "            return self._token_to_idx[token]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad2a85e",
   "metadata": {},
   "source": [
    "<h2> Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6c68fc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NMTVectorizer(object):\n",
    "    def __init__(self, source_vocab, target_vocab, max_source_length, max_target_length):\n",
    "        self.source_vocab = source_vocab\n",
    "        self.target_vocab = target_vocab\n",
    "        \n",
    "        self.max_source_length = max_source_length\n",
    "        self.max_target_length = max_target_length\n",
    "        \n",
    "\n",
    "    def _vectorize(self, indices, vector_length=-1, mask_index=0):\n",
    "\n",
    "        if vector_length < 0:\n",
    "            vector_length = len(indices)\n",
    "        \n",
    "        vector = np.zeros(vector_length, dtype=np.int64)\n",
    "        vector[:len(indices)] = indices\n",
    "        vector[len(indices):] = mask_index\n",
    "\n",
    "        return vector\n",
    "    \n",
    "    def _get_source_indices(self, text):\n",
    "        indices = [self.source_vocab.begin_seq_index]\n",
    "        indices.extend(self.source_vocab.lookup_token(token) for token in text.split(\" \"))\n",
    "        indices.append(self.source_vocab.end_seq_index)\n",
    "        return indices\n",
    "    \n",
    "    def _get_target_indices(self, text):\n",
    "        indices = [self.target_vocab.lookup_token(token) for token in text.split(\" \")]\n",
    "        indices = [self.target_vocab.begin_seq_index] + indices + [self.target_vocab.end_seq_index]\n",
    "        return indices\n",
    "        \n",
    "    def vectorize(self, source_text, target_text, use_dataset_max_lengths=True):\n",
    "        source_vector_length = -1\n",
    "        target_vector_length = -1\n",
    "        \n",
    "        if use_dataset_max_lengths:\n",
    "            source_vector_length = self.max_source_length + 2\n",
    "            target_vector_length = self.max_target_length + 2\n",
    "            \n",
    "        source_indices = self._get_source_indices(source_text)\n",
    "        source_vector = self._vectorize(source_indices, \n",
    "                                        vector_length=source_vector_length, \n",
    "                                        mask_index=self.source_vocab.mask_index)\n",
    "        \n",
    "        target_indices = self._get_target_indices(target_text)\n",
    "        target_vector = self._vectorize(target_indices,\n",
    "                                        vector_length=target_vector_length,\n",
    "                                        mask_index=self.target_vocab.mask_index)\n",
    "\n",
    "        return {\"source_vector\": source_vector, \n",
    "                \"target_vector\": target_vector, \n",
    "                \"source_length\": len(source_indices)}\n",
    "        \n",
    "    @classmethod\n",
    "    def from_dataframe(cls, bitext_df):\n",
    "\n",
    "        source_vocab = SequenceVocabulary()\n",
    "        target_vocab = SequenceVocabulary()\n",
    "        \n",
    "        max_source_length = 0\n",
    "        max_target_length = 0\n",
    "\n",
    "        for _, row in bitext_df.iterrows():\n",
    "            source_tokens = row[\"source_language\"].split(\" \")\n",
    "            if len(source_tokens) > max_source_length:\n",
    "                max_source_length = len(source_tokens)\n",
    "            for token in source_tokens:\n",
    "                source_vocab.add_token(token)\n",
    "            \n",
    "            target_tokens = row[\"target_language\"].split(\" \")\n",
    "            if len(target_tokens) > max_target_length:\n",
    "                max_target_length = len(target_tokens)\n",
    "            for token in target_tokens:\n",
    "                target_vocab.add_token(token)\n",
    "            \n",
    "        return cls(source_vocab, target_vocab, max_source_length, max_target_length)\n",
    "\n",
    "    @classmethod\n",
    "    def from_serializable(cls, contents):\n",
    "        source_vocab = SequenceVocabulary.from_serializable(contents[\"source_vocab\"])\n",
    "        target_vocab = SequenceVocabulary.from_serializable(contents[\"target_vocab\"])\n",
    "        \n",
    "        return cls(source_vocab=source_vocab, \n",
    "                   target_vocab=target_vocab, \n",
    "                   max_source_length=contents[\"max_source_length\"], \n",
    "                   max_target_length=contents[\"max_target_length\"])\n",
    "\n",
    "    def to_serializable(self):\n",
    "        return {\"source_vocab\": self.source_vocab.to_serializable(), \n",
    "                \"target_vocab\": self.target_vocab.to_serializable(), \n",
    "                \"max_source_length\": self.max_source_length,\n",
    "\n",
    "                \"max_target_length\": self.max_target_length}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bb9e5a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 512\n",
    "heads = 8\n",
    "N = 6\n",
    "batch_size = 64\n",
    "epochs = 100\n",
    "dataset = NMTDataset.load_dataset_and_make_vectorizer(\"simplest_eng_fra.csv\")\n",
    "vectorizer = dataset.get_vectorizer()\n",
    "\n",
    "src_vocab = len(vectorizer.source_vocab)\n",
    "trg_vocab = len(vectorizer.target_vocab)\n",
    "\n",
    "model = Transformer(src_vocab, trg_vocab, d_model, N, heads)\n",
    "model = model.to(\"cuda\")\n",
    "\n",
    "for p in model.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "55d0c3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8465071b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecfb40807de645c9b9697342b122a4c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4b1c83d3d974c28af9ce82a177be8ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30.546875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "<class 'dict'>\n",
      "<class 'dict'>\n",
      "<class 'dict'>\n",
      "<class 'dict'>\n",
      "<class 'dict'>\n",
      "<class 'dict'>\n",
      "<class 'dict'>\n",
      "<class 'dict'>\n",
      "<class 'dict'>\n",
      "<class 'dict'>\n",
      "<class 'dict'>\n",
      "<class 'dict'>\n",
      "<class 'dict'>\n",
      "<class 'dict'>\n",
      "<class 'dict'>\n",
      "<class 'dict'>\n",
      "<class 'dict'>\n",
      "<class 'dict'>\n",
      "<class 'dict'>\n",
      "<class 'dict'>\n",
      "<class 'dict'>\n",
      "<class 'dict'>\n",
      "<class 'dict'>\n",
      "<class 'dict'>\n",
      "<class 'dict'>\n",
      "<class 'dict'>\n",
      "<class 'dict'>\n",
      "<class 'dict'>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-78-af1b996ee232>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\optim\\optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    131\u001b[0m                     \u001b[0mstate_steps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'step'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m             F.adam(params_with_grad,\n\u001b[0m\u001b[0;32m    134\u001b[0m                    \u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m                    \u001b[0mexp_avgs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\optim\\_functional.py\u001b[0m in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[0;32m     92\u001b[0m             \u001b[0mdenom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m             \u001b[0mdenom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[0mstep_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "start = time.time()\n",
    "temp = start\n",
    "total_loss=0\n",
    "print_every=100\n",
    "for epoch in tqdm(range(epochs),total=epochs):\n",
    "    \n",
    "    model.train()\n",
    "    batch_generator = generate_nmt_batches(dataset, batch_size=64)\n",
    "    \n",
    "    for i, batch in tqdm(enumerate(batch_generator),total=len(dataset)/batch_size):\n",
    "        optim.zero_grad()\n",
    "        \n",
    "        src = batch['source']\n",
    "        trg = batch['target']\n",
    "        \n",
    "        trg_input = trg[:, :-1]\n",
    "        targets = trg[:, 1:].contiguous().view(-1)\n",
    "\n",
    "        src_mask = get_attn_mask(src,input_pad = vectorizer.source_vocab.mask_index)\n",
    "        trg_mask = get_target_attn_mask(trg_input,target_pad = vectorizer.target_vocab.mask_index)\n",
    "        preds = model(src, trg_input, src_mask, trg_mask)\n",
    "        preds = preds.view(-1, preds.size(-1)).to(\"cuda\")\n",
    "        \n",
    "        result = trg[:, 1:].contiguous().view(-1)\n",
    "        loss = F.cross_entropy(preds,result, ignore_index=vectorizer.target_vocab.mask_index)\n",
    "        \n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        if (i + 1) % print_every == 0:\n",
    "            loss_avg = total_loss / print_every\n",
    "            print(\"time = %dm, epoch %d, iter = %d, loss = %.3f,%ds per %d iters\" % \\\n",
    "                  ((time.time() - start) // 60,epoch + 1, i + 1, loss_avg, time.time() - temp,print_every))\n",
    "            total_loss = 0\n",
    "            temp = time.time()\n",
    "            \n",
    "    batch_generator = generate_nmt_batches(dataset, batch_size)\n",
    "    dataset.set_split('val')\n",
    "    running_loss = 0.\n",
    "    model.eval()\n",
    "\n",
    "    for i, batch in tqdm(enumerate(batch_generator),total=len(dataset)/batch_size):\n",
    "        \n",
    "        src = batch['source']\n",
    "        trg = batch['target']\n",
    "        \n",
    "        trg_input = trg[:, :-1]\n",
    "        targets = trg[:, 1:].contiguous().view(-1)\n",
    "        \n",
    "        src_mask = get_attn_mask(src,input_pad = vectorizer.source_vocab.mask_index)\n",
    "        trg_mask = get_target_attn_mask(trg_input,target_pad = vectorizer.target_vocab.mask_index)\n",
    "        \n",
    "        preds = model(src, trg_input, src_mask, trg_mask)\n",
    "        preds = preds.view(-1, preds.size(-1)).to(\"cuda\")\n",
    "        result = trg[:, 1:].contiguous().view(-1)\n",
    "        loss = F.cross_entropy(preds,result, ignore_index=vectorizer.target_vocab.mask_index)\n",
    "        running_loss += (loss.item() - running_loss) / (i + 1)\n",
    "        \n",
    "    print(\"validation: epoch %d, loss = %.3f,\" % (epoch + 1, running_loss) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d6768d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_source_sentence(vectorizer, batch_dict, index):\n",
    "    indices = batch_dict['source'][index].cpu().data.numpy()\n",
    "    vocab = vectorizer.source_vocab\n",
    "    return sentence_from_indices(indices, vocab)\n",
    "\n",
    "def get_true_sentence(vectorizer, batch_dict, index):\n",
    "    return sentence_from_indices(batch_dict['target'].cpu().data.numpy()[index], vectorizer.target_vocab)\n",
    "    \n",
    "def get_sampled_sentence(vectorizer, batch_dict, index):\n",
    "    y_pred = model(batch_dict['source'], batch_dict['target'],False,False )\n",
    "    return sentence_from_indices(torch.max(y_pred, dim=2)[1].cpu().data.numpy()[index], vectorizer.target_vocab)\n",
    "\n",
    "def get_all_sentences(vectorizer, batch_dict, index):\n",
    "    return {\"source\": get_source_sentence(vectorizer, batch_dict, index), \n",
    "            \"truth\": get_true_sentence(vectorizer, batch_dict, index), \n",
    "            \"sampled\": get_sampled_sentence(vectorizer, batch_dict, index)}\n",
    "    \n",
    "def sentence_from_indices(indices, vocab, strict=True):\n",
    "    ignore_indices = set([vocab.mask_index, vocab.begin_seq_index, vocab.end_seq_index])\n",
    "    out = []\n",
    "    for index in indices:\n",
    "        if index == vocab.begin_seq_index and strict:\n",
    "            continue\n",
    "        elif index == vocab.end_seq_index and strict:\n",
    "            return \" \".join(out)\n",
    "        else:\n",
    "            out.append(vocab.lookup_index(index))\n",
    "    return \" \".join(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1025,
   "id": "e3217f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.set_split('test')\n",
    "batch_generator = generate_nmt_batches(dataset, \n",
    "                                       batch_size=batch_size)\n",
    "batch_dict = next(batch_generator)\n",
    "\n",
    "model = model.eval().to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1022,
   "id": "ebea9edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = \"There is no need It is my treat\"\n",
    "target = \"Il n'y a pas besoin C'est mon régal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1023,
   "id": "6ea0b360",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = vectorizer.vectorize(source,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1024,
   "id": "9e1c2ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_dict['source'][1] = torch.from_numpy(vector['source_vector'])\n",
    "batch_dict['target'][1] = torch.from_numpy(vector['target_vector'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1026,
   "id": "db618f43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = get_all_sentences(vectorizer, batch_dict, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1027,
   "id": "359c21bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': \"you 're <UNK> .\", 'truth': 'tu es <UNK> .', 'sampled': 'tu es parfait .'}\n",
      "{'source': \"you 're disgusting .\", 'truth': 'vous êtes <UNK> .', 'sampled': 'vous êtes dégoûtante .'}\n",
      "{'source': \"you 're resourceful .\", 'truth': 'vous êtes pleine de ressources .', 'sampled': 'vous êtes pleine de ressources .'}\n",
      "{'source': \"i 'm stubborn .\", 'truth': 'je suis obstinée .', 'sampled': 'je suis obstinée .'}\n",
      "{'source': \"he 's <UNK> .\", 'truth': 'il est peu sûr de lui .', 'sampled': 'il est jaloux jaloux de lui .'}\n",
      "{'source': \"you 're big .\", 'truth': 'tu es grande .', 'sampled': 'tu es grande .'}\n",
      "{'source': \"you 're correct .\", 'truth': 'tu as raison .', 'sampled': 'tu as raison .'}\n",
      "{'source': \"i 'm ruthless .\", 'truth': 'je suis impitoyable .', 'sampled': 'je suis impitoyable .'}\n",
      "{'source': \"i 'm ready !\", 'truth': 'je suis prête !', 'sampled': 'je suis prête !'}\n",
      "{'source': \"she 's strong-willed .\", 'truth': 'elle est obstinée .', 'sampled': 'elle est très .'}\n",
      "{'source': \"they 're dangerous .\", 'truth': 'ils sont dangereux .', 'sampled': 'ils sont dangereuses .'}\n",
      "{'source': \"you 're invited .\", 'truth': 'vous êtes invitées .', 'sampled': 'vous êtes invitées .'}\n",
      "{'source': \"you 're very smart .\", 'truth': 'tu es très intelligent .', 'sampled': 'tu es très intelligent .'}\n",
      "{'source': \"we 're all going .\", 'truth': 'nous y allons tous .', 'sampled': 'nous y allons tous .'}\n",
      "{'source': 'he is a psychic .', 'truth': \"c'est un voyant .\", 'sampled': \"c'est un voyant .\"}\n",
      "{'source': \"we 're very grateful .\", 'truth': 'nous sommes très reconnaissants .', 'sampled': 'nous sommes très reconnaissants .'}\n",
      "{'source': \"we 're all different .\", 'truth': 'nous sommes tous différents .', 'sampled': 'nous sommes tous différents .'}\n",
      "{'source': \"i 'm your partner .\", 'truth': 'je suis ton partenaire .', 'sampled': 'je suis ton partenaire .'}\n",
      "{'source': \"we 're all <UNK> .\", 'truth': 'nous sommes toutes <UNK> .', 'sampled': 'nous sommes toutes deux .'}\n",
      "{'source': \"you 're very stylish .\", 'truth': 'vous êtes fort élégante .', 'sampled': 'vous êtes fort élégante .'}\n",
      "{'source': \"we 're all bored .\", 'truth': 'nous nous ennuyons tous .', 'sampled': 'nous nous ennuyons tous .'}\n",
      "{'source': \"you 're scaring me .\", 'truth': 'tu me fais peur .', 'sampled': 'tu me fais enfants .'}\n",
      "{'source': \"we 're studying chinese .\", 'truth': 'nous étudions le chinois .', 'sampled': 'nous étudions le chinois .'}\n",
      "{'source': \"i 'm not your enemy .\", 'truth': 'je ne suis pas votre ennemie .', 'sampled': 'je ne suis pas votre ennemie .'}\n",
      "{'source': \"you 're always <UNK> trouble .\", 'truth': 'vous <UNK> toujours des ennuis .', 'sampled': 'vous êtes toujours des ennuis .'}\n",
      "{'source': \"you 're taller than me .\", 'truth': 'tu es plus grande que moi .', 'sampled': 'tu es plus grande que moi .'}\n",
      "{'source': 'he is a quiet man .', 'truth': \"c'est un homme <UNK> .\", 'sampled': \"c'est un homme calme .\"}\n",
      "{'source': 'she is just going shopping .', 'truth': 'elle va juste faire des emplettes .', 'sampled': 'elle va simplement des des emplettes .'}\n",
      "{'source': \"they 're mad at you .\", 'truth': 'ils sont furieux après vous .', 'sampled': 'ils sont furieux après vous .'}\n",
      "{'source': \"they 're very close friends .\", 'truth': 'ce sont des amies très proches .', 'sampled': \"ce sont des amies lorsqu'elles proche .\"}\n",
      "{'source': \"you 're going to die .\", 'truth': 'vous allez mourir .', 'sampled': 'vous allez mourir .'}\n",
      "{'source': \"he 's my older brother .\", 'truth': \"c'est mon frère aîné .\", 'sampled': \"c'est mon frère cadet .\"}\n",
      "{'source': \"i 'm <UNK> years old .\", 'truth': \"j'ai <UNK> ans .\", 'sampled': \"j'ai l'estomac . .\"}\n",
      "{'source': 'he is proficient in english .', 'truth': 'il est très compétent en anglais .', 'sampled': 'il est très anglais en anglais .'}\n",
      "{'source': \"i 'm a normal guy .\", 'truth': 'je suis un type normal .', 'sampled': 'je suis un type normal .'}\n",
      "{'source': \"i 'm beginning to get curious .\", 'truth': 'je commence à devenir curieuse .', 'sampled': 'je commence à être curieuse .'}\n",
      "{'source': \"i 'm delighted to meet you .\", 'truth': 'je suis enchanté de te rencontrer .', 'sampled': 'je suis enchanté de te rencontrer .'}\n",
      "{'source': 'she is as beautiful as ever .', 'truth': 'elle est belle , comme toujours .', 'sampled': 'elle est belle , plus il .'}\n",
      "{'source': \"i 'm very busy this week .\", 'truth': 'je suis très occupé cette semaine .', 'sampled': 'je suis très occupé cette semaine .'}\n",
      "{'source': 'i am thinking about that matter .', 'truth': 'je suis en train de penser à cette affaire .', 'sampled': 'je suis en train de penser à cette affaire .'}\n",
      "{'source': \"i 'm kind of busy tonight .\", 'truth': 'je suis plutôt occupé , ce soir .', 'sampled': 'je suis plutôt occupé , ce soir .'}\n",
      "{'source': \"we 're getting out of here .\", 'truth': \"nous partons d'ici .\", 'sampled': \"nous sortons d'ici .\"}\n",
      "{'source': \"we 're so proud of you !\", 'truth': 'nous sommes tellement fiers de vous !', 'sampled': 'nous sommes tellement fières de vous !'}\n",
      "{'source': \"i 'm ready if you are .\", 'truth': \"je suis prêt si tu l'es .\", 'sampled': \"je suis prêt si tu l'es .\"}\n",
      "{'source': \"i 'm sure that he 's happy .\", 'truth': \"je suis certain qu'il est heureux .\", 'sampled': \"je suis certain qu'il est heureux .\"}\n",
      "{'source': 'you are not supposed to smoke here .', 'truth': \"vous n'êtes pas censée fumer ici .\", 'sampled': \"vous n'êtes pas censée fumer ici .\"}\n",
      "{'source': \"i 'm giving my old books away .\", 'truth': 'je donne mes vieux livres .', 'sampled': 'je donne mes vieux bouquins .'}\n",
      "{'source': \"i 'm at a friend 's house .\", 'truth': 'je suis chez une amie .', 'sampled': 'je suis chez une amie .'}\n",
      "{'source': \"i 'm going to buy some bread .\", 'truth': 'je vais acheter du pain .', 'sampled': 'je vais acheter du même .'}\n",
      "{'source': \"we 're all to blame for that .\", 'truth': \"c'est de notre faute , à tous .\", 'sampled': \"c'est de notre force à à ça .\"}\n",
      "{'source': 'she is engaged to a rich man .', 'truth': 'elle est fiancée à un homme riche .', 'sampled': 'elle est fiancée à un riche . .'}\n",
      "{'source': \"i 'm going on a business trip .\", 'truth': \"je pars en voyage d'affaire .\", 'sampled': 'je pars en affaires . .'}\n",
      "{'source': 'you are the tallest of us all .', 'truth': 'tu es le plus grand de nous tous .', 'sampled': 'tu es le plus grand de nous sommes .'}\n",
      "{'source': 'she is always complaining of her small salary .', 'truth': 'elle se plaint sans arrêt de son faible salaire .', 'sampled': 'elle se plaint toujours mère de son faible salaire .'}\n",
      "{'source': \"we 're just about finished for the day .\", 'truth': \"nous avons presque fini pour aujourd'hui .\", 'sampled': 'nous avons presque fini pour jour .'}\n",
      "{'source': \"i 'm sorry to bother you so often .\", 'truth': 'je suis désolé de vous déranger si souvent .', 'sampled': 'je suis désolé de vous déranger si souvent .'}\n",
      "{'source': \"you 're more beautiful than i remember you .\", 'truth': 'tu es plus belle que dans mon souvenir .', 'sampled': 'tu es plus belle que dans mon souvenir .'}\n",
      "{'source': \"you 're not really a millionaire , are you ?\", 'truth': \"vous n'êtes pas vraiment millionnaire , si ?\", 'sampled': \"vous n'êtes pas vraiment millionnaire , si ?\"}\n",
      "{'source': \"i 'm sorry that i did n't reply sooner .\", 'truth': 'désolé de ne pas avoir répondu plus tôt .', 'sampled': 'désolé de ne pas avoir répondu plus tôt .'}\n",
      "{'source': \"i 'm in debt to my uncle for <UNK> <UNK> .\", 'truth': 'je dois dix mille dollars à mon oncle .', 'sampled': 'je dois oncle ans à à mon oncle .'}\n",
      "{'source': \"i 'm not angry at you , just very disappointed .\", 'truth': 'je ne suis pas en colère après toi , seulement très déçu .', 'sampled': 'je ne suis pas en colère après toi , seulement très déçu .'}\n",
      "{'source': 'we are going to have a party on saturday night .', 'truth': 'nous allons faire une fête samedi soir .', 'sampled': \"nous allons faire une fête d'anniversaire . .\"}\n",
      "{'source': \"i 'm not buying you another drink until you say sorry .\", 'truth': 'tant que tu ne te <UNK> pas excusé , je ne te <UNK> pas un autre verre .', 'sampled': \"pas que tu ne te peut jusqu'à pouvoir avant je te te donner . reconnu autre . .\"}\n",
      "{'source': \"we 're less than halfway to the top of the mountain . are you already tired ?\", 'truth': 'nous sommes à moins de la moitié du chemin du sommet . es-tu vraiment déjà fatiguée ?', 'sampled': 'nous sommes à moins de la moitié du chemin du sommet . es-tu vraiment déjà fatiguée ?'}\n"
     ]
    }
   ],
   "source": [
    "for i in range(64):\n",
    "    print(get_all_sentences(vectorizer, batch_dict, i))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
