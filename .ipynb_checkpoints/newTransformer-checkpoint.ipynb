{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb51609a",
   "metadata": {},
   "source": [
    "<h2> Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b611d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "import math\n",
    "import pandas as pd\n",
    "from torch.nn import functional as F\n",
    "import copy\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cee7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedder(nn.Module): #임베딩 레이어\n",
    "    def __init__(self,vocab_size,d_model):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size,d_model)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        #x= x.to(\"cpu\")\n",
    "        return self.embed(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764751d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = Embedder(32000,768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba3257d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "idx = torch.tensor([1,2,3])\n",
    "e(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42b69a9",
   "metadata": {},
   "source": [
    "<h2> Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c8458c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ba0a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoder(nn.Module): #위치 인코딩 레이어\n",
    "    def __init__(self, d_model, max_seq_len = 128):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        #위치 인코딩 초기화\n",
    "        positional_encoding = torch.zeros(max_seq_len, d_model)\n",
    "        \n",
    "        for pos in range(max_seq_len):\n",
    "            for i in range(0, d_model, 2):\n",
    "                positional_encoding[pos, i] = math.sin(pos / (10000 ** ((2 * i)/d_model)))\n",
    "                positional_encoding[pos, i + 1] = math.cos(pos / (10000 ** ((2 * (i + 1))/d_model)))\n",
    "                \n",
    "        positional_encoding = positional_encoding.unsqueeze(0)\n",
    "        #잔차 연결\n",
    "        self.register_buffer('positional_encoding', positional_encoding)\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = x * math.sqrt(self.d_model)\n",
    "        seq_len = x.size(1)\n",
    "        x = x + self.positional_encoding[:,:seq_len]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361f9984",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = PositionalEncoder(768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229e31cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred값 대충 생성\n",
    "input_seq = torch.randint(0,40,(128,))\n",
    "emb = e(input_seq)\n",
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0c8758",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = p(emb.to(\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73072b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y값 대충 생성\n",
    "input_seq2 = torch.randint(0,40,(128,))\n",
    "emb2 = e(input_seq2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ec263b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = p(emb2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5693904c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.mean((y_pred - y)**2)\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bc27cb",
   "metadata": {},
   "source": [
    "<h2> Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7d1c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attn_mask(input_seq,input_pad):\n",
    "    return (input_seq != input_pad).unsqueeze(1).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251c0c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_attn_mask(target_seq,target_pad):\n",
    "    target_mask = (target_seq != target_pad).unsqueeze(1)\n",
    "    size = target_seq.size(1)\n",
    "    nopeak_mask = np.triu(np.ones((1,size,size)),k=1).astype('uint8')\n",
    "    nopeak_mask = torch.from_numpy(nopeak_mask) == 0\n",
    "    nopeak_mask = nopeak_mask.to(\"cuda\")\n",
    "    target_mask = target_mask & nopeak_mask\n",
    "    return target_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9f5650",
   "metadata": {},
   "source": [
    "<h2> Self-Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08775d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b100bf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention(query, key, value, d_k, attention_mask=False, dropout=None):\n",
    "    \n",
    "    scores = torch.matmul(query,key.transpose(-2,-1)) /  math.sqrt(d_k)\n",
    "    \n",
    "    if attention_mask is True:\n",
    "        attention_mask = get_attn_mask(scores,0)\n",
    "        attention_mask = attention_mask.unsqueeze(1)\n",
    "        scores = scores.masked_fill(attention_mask == 0, -1e9)\n",
    "    \n",
    "    scores = F.softmax(scores, dim=-1)\n",
    "    \n",
    "    if dropout is not None:\n",
    "        scores = dropout(scores)\n",
    "        \n",
    "    output = torch.matmul(scores, value)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318955dc",
   "metadata": {},
   "source": [
    "<h2> Multi-Headed Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e10e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fe1122",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self,heads,d_model,dropout_rate = 0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.d_k = d_model // heads\n",
    "        self.h = heads\n",
    "        \n",
    "        self.query_layer = nn.Linear(d_model,d_model)\n",
    "        self.key_layer = nn.Linear(d_model,d_model)\n",
    "        self.value_layer = nn.Linear(d_model,d_model)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.out_layer = nn.Linear(d_model,d_model)\n",
    "        \n",
    "    def forward(self,query,key,value,attention_mask = True):\n",
    "        \n",
    "        batch_size = query.size(0)\n",
    "        \n",
    "        query = self.key_layer(query).view(batch_size,-1,self.h,self.d_k)\n",
    "        key = self.key_layer(key).view(batch_size,-1,self.h,self.d_k)\n",
    "        value = self.key_layer(value).view(batch_size,-1,self.h,self.d_k)\n",
    "        \n",
    "        query =  query.transpose(1,2)\n",
    "        key = key.transpose(1,2)\n",
    "        value = value.transpose(1,2)\n",
    "        \n",
    "        scores = attention(query,key,value,self.d_k,attention_mask,self.dropout)\n",
    "        Z = scores.transpose(1,2).contiguous().view(batch_size,-1,self.d_model)\n",
    "        output = self.dropout(Z)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8dd240",
   "metadata": {},
   "outputs": [],
   "source": [
    "mha = MultiHeadAttention(8,512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c769adcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = torch.rand((1,3,512))\n",
    "key = torch.rand((1,3,512))\n",
    "value = torch.rand((1,3,512))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07160d0e",
   "metadata": {},
   "source": [
    "<h2> Feed-Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2739259",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self,d_model,d_ff = 2048,dropout = 0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(d_model,d_ff)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(d_ff,d_model)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127591b0",
   "metadata": {},
   "source": [
    "<h2> Normalisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fdeb25",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>prevents the range of value in the layers changing too much\n",
    "<li>it makes model trains faster and has better ability</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51067e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Norm(nn.Module):\n",
    "    def __init__(self,d_model,eps = 1e-6):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.size = d_model\n",
    "        \n",
    "        self.alpha = nn.Parameter(torch.ones(self.size))\n",
    "        self.bias = nn.Parameter(torch.zeros(self.size))\n",
    "        self.eps = eps\n",
    "    \n",
    "    def forward(self,x):\n",
    "        norm = self.alpha *(x - x.mean(dim = -1,keepdim=True)) / (x.std(dim=-1, keepdim=True) + self.eps) + self.bias\n",
    "        return norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8dab34",
   "metadata": {},
   "source": [
    "<h1> ★Encoder&Decoder Layer★"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed717f39",
   "metadata": {},
   "source": [
    "<ui>\n",
    "<li> build an encoder layer with one multi-head attention layer and one feed-forward layer </li>\n",
    "</ui>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c831f6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self,d_model,heads,dropout = 0.1):\n",
    "        super().__init__()\n",
    "        self.norm1 = Norm(d_model)\n",
    "        self.norm2 = Norm(d_model)\n",
    "        self.mha = MultiHeadAttention(heads,d_model)\n",
    "        self.ff = FeedForward(d_model)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self,x,mask):\n",
    "        x2 = self.norm1(x)\n",
    "        x = x + self.dropout1(self.mha(x2,x2,x2,mask))\n",
    "        x2 = self.norm2(x)\n",
    "        x = x + self.dropout2(self.ff(x2))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de23f8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self,d_model,heads,dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.norm1 = Norm(d_model)\n",
    "        self.norm2 = Norm(d_model)\n",
    "        self.norm3 = Norm(d_model)\n",
    "        \n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.dropout3 = nn.Dropout(dropout)\n",
    "        \n",
    "        self.mha1 = MultiHeadAttention(heads, d_model)\n",
    "        self.mha2 = MultiHeadAttention(heads, d_model)\n",
    "        self.ff = FeedForward(d_model)\n",
    "        \n",
    "    def forward(self,x,encoder_outputs,src_mask,trg_mask):\n",
    "        x2 = self.norm1(x)\n",
    "        x = x + self.dropout1(self.mha1(x2,x2,x2,trg_mask))\n",
    "        \n",
    "        x2 = self.norm2(x)\n",
    "        x = x + self.dropout2(self.mha2(x2,encoder_outputs,encoder_outputs,src_mask))\n",
    "        \n",
    "        x2 = self.norm3(x)\n",
    "        x = x + self.dropout3(self.ff(x2))\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edbc29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a conveinient cloning function that can generate multiple layers\n",
    "import copy\n",
    "def get_clones(module,N):\n",
    "    return nn.ModuleList([copy.deepcopy(module) for i in range(N)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997feb4b",
   "metadata": {},
   "source": [
    "<h1> Encoder Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45796bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self,vocab_size,d_model,N,heads):\n",
    "        super().__init__()\n",
    "        self.N = N\n",
    "        self.embed = Embedder(vocab_size,d_model)\n",
    "        self.pe = PositionalEncoder(d_model)\n",
    "        self.layers = get_clones(EncoderLayer(d_model,heads),N)\n",
    "        self.norm = Norm(d_model)\n",
    "    \n",
    "    def forward(self,src,mask):\n",
    "        x = self.embed(src)\n",
    "        x = self.pe(x)\n",
    "        for i in range(self.N):\n",
    "            x = self.layers[i](x,mask)\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae1079c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self,vocab_size,d_model,N,heads):\n",
    "        super().__init__()\n",
    "        self.N = N\n",
    "        self.embed = Embedder(vocab_size,d_model)\n",
    "        self.pe = PositionalEncoder(d_model)\n",
    "        self.layers = get_clones(DecoderLayer(d_model,heads),N)\n",
    "        self.norm = Norm(d_model)\n",
    "    def forward(self,target,encoder_outputs,src_mask,target_mask):\n",
    "        x = self.embed(target)\n",
    "        x = self.pe(x)\n",
    "        for i in range(self.N):\n",
    "            x = self.layers[i](x,encoder_outputs,src_mask,target_mask)\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f651336b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, src_vocab, trg_vocab, d_model, N, heads):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(src_vocab, d_model, N, heads)\n",
    "        self.decoder = Decoder(trg_vocab, d_model, N, heads)\n",
    "        self.out = nn.Linear(d_model, trg_vocab)\n",
    "    def forward(self, src, trg, src_mask, trg_mask):\n",
    "        e_outputs = self.encoder(src, src_mask)\n",
    "        d_output = self.decoder(trg, e_outputs, src_mask, trg_mask)\n",
    "        output = self.out(d_output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6c73ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from transformers import FlaubertTokenizer\n",
    "\n",
    "eng_tokenizer = Tokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "french_tokenizer = FlaubertTokenizer.from_pretrained('flaubert/flaubert_base_cased')\n",
    "\n",
    "eng_vocab = eng_tokenizer.get_vocab()\n",
    "french_vocab = french_tokenizer.get_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9e5a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 512\n",
    "heads = 8\n",
    "N = 6\n",
    "batch_size = 24\n",
    "epochs = 50\n",
    "\n",
    "src_vocab = len(eng_vocab)\n",
    "trg_vocab = len(french_vocab)\n",
    "\n",
    "model = Transformer(src_vocab, trg_vocab, d_model, N, heads)\n",
    "model = model.to(\"cuda\")\n",
    "\n",
    "for p in model.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9338c34d",
   "metadata": {},
   "source": [
    "<h2> Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2230756",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self, dataset, eng_tokenizer,french_tokenizer,max_len = 64,source = \"source_language\",target = \"target_language\"):\n",
    "        self.max_len = max_len\n",
    "        self.sources = []\n",
    "        self.targets = []\n",
    "        self.source_lengths = []\n",
    "        \n",
    "        for i,row in dataset.iterrows():\n",
    "            ids = eng_tokenizer.encode(row[source]).ids\n",
    "            self.sources.append(self.padding(ids))\n",
    "            self.source_lengths.append(len(ids))\n",
    "            self.targets.append(self.padding(french_tokenizer.encode(row[target])))\n",
    "        \n",
    "    def padding(self,ids):\n",
    "        pad = np.zeros(self.max_len, dtype=np.int64)\n",
    "        pad[:len(ids)] = ids\n",
    "        return pad\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return {\"source\" : self.sources[i],\n",
    "                \"target\" : self.targets[i],\n",
    "                \"source_length\" : self.source_lengths[i]\n",
    "               }\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.sources))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f86304",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"simplest_eng_fra.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fd7efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[df.split=='train']\n",
    "train_size = len(train_df)\n",
    "val_df = df[df.split=='val']\n",
    "validation_size = len(val_df)\n",
    "test_df = df[df.split=='test']\n",
    "test_size = len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa518aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dataset = Dataset(train_df,eng_tokenizer,french_tokenizer)\n",
    "valid_dataset = Dataset(val_df,eng_tokenizer,french_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9be6455",
   "metadata": {},
   "source": [
    "<h2> DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e17aa2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "def load_data(dataset, batch_size, shuffle=True, \n",
    "                            drop_last=True, device=\"cuda\"):\n",
    "\n",
    "    dataloader = DataLoader(dataset=dataset, batch_size=batch_size,\n",
    "                            shuffle=shuffle, drop_last=drop_last)\n",
    "\n",
    "    for data_dict in dataloader:\n",
    "        lengths = data_dict['source_length'].numpy()\n",
    "        sorted_length_indices = lengths.argsort().tolist()\n",
    "        out_data_dict = {}\n",
    "        for name, tensor in data_dict.items():\n",
    "            out_data_dict[name] = data_dict[name][sorted_length_indices].to(device)\n",
    "        yield out_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8465071b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "temp = start\n",
    "total_loss=0\n",
    "print_every=100\n",
    "for epoch in tqdm(range(epochs),total=epochs):\n",
    "    model.train()\n",
    "    \n",
    "    \n",
    "    batch_generator = load_data(train_dataset, batch_size)\n",
    "    \n",
    "    for i, batch in tqdm(enumerate(batch_generator),total=train_size/batch_size):\n",
    "        optim.zero_grad()\n",
    "        \n",
    "        src = batch['source']\n",
    "        trg = batch['target']\n",
    "        \n",
    "        trg_input = trg[:, :-1]\n",
    "        targets = trg[:, 1:].contiguous().view(-1)\n",
    "\n",
    "        src_mask = get_attn_mask(src,input_pad = 0)\n",
    "        trg_mask = get_target_attn_mask(trg_input,target_pad = 0)\n",
    "        preds = model(src, trg_input, src_mask, trg_mask)\n",
    "        preds = preds.view(-1, preds.size(-1)).to(\"cuda\")\n",
    "        \n",
    "        result = trg[:, 1:].contiguous().view(-1)\n",
    "        loss = F.cross_entropy(preds,result, ignore_index=0)\n",
    "        \n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        if (i + 1) % print_every == 0:\n",
    "            loss_avg = total_loss / print_every\n",
    "            print(\"time = %dm, epoch %d, iter = %d, loss = %.3f,%ds per %d iters\" % \\\n",
    "                  ((time.time() - start) // 60,epoch + 1, i + 1, loss_avg, time.time() - temp,print_every))\n",
    "            total_loss = 0\n",
    "            temp = time.time()\n",
    "            \n",
    "    batch_generator = load_data(valid_dataset, batch_size)\n",
    "    running_loss = 0.\n",
    "    model.eval()\n",
    "\n",
    "    for i, batch in tqdm(enumerate(batch_generator),total=validation_size/batch_size):\n",
    "        \n",
    "        src = batch['source']\n",
    "        trg = batch['target']\n",
    "        \n",
    "        trg_input = trg[:, :-1]\n",
    "        targets = trg[:, 1:].contiguous().view(-1)\n",
    "        \n",
    "        src_mask = get_attn_mask(src,input_pad = 0)\n",
    "        trg_mask = get_target_attn_mask(trg_input,target_pad = 0)\n",
    "        \n",
    "        preds = model(src, trg_input, src_mask, trg_mask)\n",
    "        preds = preds.view(-1, preds.size(-1)).to(\"cuda\")\n",
    "        result = trg[:, 1:].contiguous().view(-1)\n",
    "        loss = F.cross_entropy(preds,result, ignore_index=0)\n",
    "        running_loss += (loss.item() - running_loss) / (i + 1)\n",
    "        \n",
    "    print(\"validation: epoch %d, loss = %.3f,\" % (epoch + 1, running_loss) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "55d6768d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_source_sentence(source_vocab, batch_dict, index):\n",
    "    indices = batch_dict['source'][index].cpu().data.numpy()\n",
    "    return sentence_from_indices(indices, source_vocab)\n",
    "\n",
    "def get_true_sentence(target_vocab, batch_dict, index):\n",
    "    return sentence_from_indices(batch_dict['target'].cpu().data.numpy()[index], target_vocab)\n",
    "    \n",
    "def get_sampled_sentence(target_vocab, batch_dict, index):\n",
    "    y_pred = model(batch_dict['source'], batch_dict['target'],False,False )\n",
    "    return sentence_from_indices(torch.max(y_pred, dim=2)[1].cpu().data.numpy()[index], target_vocab)\n",
    "\n",
    "def get_all_sentences(source_vocab,target_vocab, batch_dict, index):\n",
    "    return {\"source\": get_source_sentence(source_vocab, batch_dict, index), \n",
    "            \"truth\": get_true_sentence(target_vocab, batch_dict, index), \n",
    "            \"sampled\": get_sampled_sentence(target_vocab, batch_dict, index)}\n",
    "    \n",
    "def sentence_from_indices(indices, vocab, strict=True):\n",
    "    ignore_indices = set([0,1,2,5])\n",
    "    vocab_map = dict(map(reversed,vocab.items()))\n",
    "    out = []\n",
    "    for index in indices:\n",
    "        if index == 0 and strict:\n",
    "            continue\n",
    "        elif index == 1 and strict:\n",
    "            return \" \".join(out)\n",
    "        else:\n",
    "            out.append(vocab_map[index])\n",
    "    return \" \".join(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e3217f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = Dataset(test_df,eng_tokenizer,french_tokenizer)\n",
    "batch_generator = load_data(test_dataset, \n",
    "                                       batch_size=batch_size)\n",
    "batch_dict = next(batch_generator)\n",
    "\n",
    "model = model.eval().to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ebea9edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = \"There is no need It is my treat\"\n",
    "target = \"Il n'y a pas besoin C'est mon régal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f4207a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_vector = [0 for i in range(64)]\n",
    "source_ids = eng_tokenizer.encode(source).ids\n",
    "source_vector[:len(source_ids)] = source_ids\n",
    "source_vector = np.array(source_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5f60d463",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_vector = [0 for i in range(64)]\n",
    "target_ids = french_tokenizer.encode(target)\n",
    "target_vector[:len(target_ids)] = target_ids\n",
    "target_vector = np.array(target_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f5e89d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = {'source_vector' : target_vector,\n",
    "         'target_vector' : source_vector}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9e1c2ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_dict['source'][1] = torch.from_numpy(vector['source_vector'])\n",
    "batch_dict['target'][1] = torch.from_numpy(vector['target_vector'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "db618f43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = get_all_sentences(eng_vocab,french_vocab, batch_dict, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "359c21bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': '[CLS] he is foolish . [SEP]', 'truth': 'il</w> est</w> idiot</w> .</w>', 'sampled': 'il</w> est</w> idiot</w> .</w>'}\n",
      "{'source': '[unused58] [unused50] [unused65] [unused33] [unused41] [unused401] [unused108] [unused26] [unused146] ##horpe', 'truth': 'ils</w> commencer</w> spectacle</w> Dé banques</w> température</w> spectacle</w> appui</w> Tél</w> sans</w>', 'sampled': \"il</w> commencer</w> ille</w> our our j'</w> ûment</w> ûment</w> sans</w> sans</w> sans</w> sans</w> si</w> si</w> si</w> d'</w> encore</w> par</w> encore</w> encore</w> encore</w> encore</w> encore</w> encore</w> encore</w> je</w> je</w> je</w> je</w> je</w> je</w> je</w> je</w> je</w> je</w> je</w> c'</w> je</w> je</w> je</w> je</w> c'</w> c'</w> c'</w> je</w> je</w> je</w> j'</w> j'</w> j'</w> j'</w> j'</w> j'</w> j'</w> c'</w> je</w> je</w> je</w> je</w> je</w> j'</w> j'</w> j'</w> j'</w>\"}\n",
      "{'source': \"[CLS] we ' re coming . [SEP]\", 'truth': 'nous</w> venons</w> .</w>', 'sampled': 'nous</w> restons</w> .</w>'}\n",
      "{'source': \"[CLS] you ' re forgiven . [SEP]\", 'truth': 'vous</w> êtes</w> par donnée</w> .</w>', 'sampled': 'vous</w> êtes</w> par donnée</w> .</w>'}\n",
      "{'source': \"[CLS] they ' re dancing . [SEP]\", 'truth': 'elles</w> sont</w> en</w> train</w> de</w> danser</w> .</w>', 'sampled': 'elles</w> sont</w> en</w> train</w> de</w> danser</w> .</w>'}\n",
      "{'source': '[CLS] he is good at singing . [SEP]', 'truth': 'il</w> est</w> bon</w> chanteur</w> .</w>', 'sampled': 'il</w> est</w> bon</w> chanteur</w> .</w>'}\n",
      "{'source': \"[CLS] he ' s very ill . [SEP]\", 'truth': 'il</w> est</w> fort</w> malade</w> .</w>', 'sampled': 'il</w> est</w> fort</w> malade</w> .</w>'}\n",
      "{'source': \"[CLS] i ' m just tired . [SEP]\", 'truth': 'je</w> suis</w> seulement</w> fatigué</w> .</w>', 'sampled': 'je</w> suis</w> seulement</w> fatigué</w> .</w>'}\n",
      "{'source': \"[CLS] he ' s running for congress . [SEP]\", 'truth': 'il</w> est</w> candidat</w> au</w> congrès</w> .</w>', 'sampled': 'il</w> est</w> accroché</w> au</w> golf</w> .</w>'}\n",
      "{'source': \"[CLS] you ' re part of this . [SEP]\", 'truth': 'vous</w> en</w> faites</w> partie</w> .</w>', 'sampled': 'vous</w> en</w> faites</w> partie</w> .</w>'}\n",
      "{'source': \"[CLS] i ' m not bragg ##ing . [SEP]\", 'truth': 'je</w> ne</w> fri me</w> pas</w> .</w>', 'sampled': 'je</w> ne</w> fri fri suis</w> .</w>'}\n",
      "{'source': \"[CLS] i ' m studying french grammar . [SEP]\", 'truth': \"je</w> suis</w> en</w> train</w> d'</w> étudier</w> la</w> grammaire</w> française</w> .</w>\", 'sampled': \"je</w> suis</w> en</w> train</w> d'</w> étudier</w> la</w> date</w> française</w> .</w>\"}\n",
      "{'source': \"[CLS] you ' re very tim ##id . [SEP]\", 'truth': 'vous</w> êtes</w> très</w> crain tif</w> .</w>', 'sampled': 'vous</w> êtes</w> très</w> crain tif</w> .</w>'}\n",
      "{'source': \"[CLS] you ' re such a liar . [SEP]\", 'truth': 'tu</w> es</w> une</w> sacrée</w> ment euse</w> .</w>', 'sampled': 'tu</w> es</w> une</w> sacrée</w> ment euse</w> .</w>'}\n",
      "{'source': \"[CLS] i ' m not a liar . [SEP]\", 'truth': 'je</w> ne</w> suis</w> pas</w> une</w> ment euse</w> .</w>', 'sampled': 'je</w> ne</w> suis</w> pas</w> une</w> ment euse</w> .</w>'}\n",
      "{'source': \"[CLS] he ' s now aboard the ship . [SEP]\", 'truth': 'il</w> est</w> maintenant</w> à</w> bord</w> du</w> bateau</w> .</w>', 'sampled': 'il</w> est</w> maintenant</w> à</w> présent</w> du</w> bateau</w> .</w>'}\n",
      "{'source': '[CLS] i am yours and you are mine . [SEP]', 'truth': 'je</w> suis</w> tienne</w> et</w> tu</w> es</w> mienne</w> .</w>', 'sampled': 'je</w> suis</w> sienne</w> et</w> tu</w> es</w> mienne</w> .</w>'}\n",
      "{'source': \"[CLS] i ' m the boss around here . [SEP]\", 'truth': \"c'</w> est</w> moi</w> le</w> patron</w> ,</w> par</w> ici</w> .</w>\", 'sampled': \"c'</w> est</w> moi</w> le</w> patron</w> ,</w> par</w> ici</w> .</w>\"}\n",
      "{'source': \"[CLS] i ' m not an early rise ##r . [SEP]\", 'truth': 'je</w> me</w> lève</w> tard</w> le</w> matin</w> .</w>', 'sampled': 'je</w> me</w> dépasse</w> tard</w> le</w> matin</w> .</w>'}\n",
      "{'source': \"[CLS] i ' m glad you ' re ok again . [SEP]\", 'truth': 'je</w> suis</w> contente</w> que</w> vous</w> alli ez</w> à</w> nouveau</w> bien</w> .</w>', 'sampled': 'je</w> suis</w> contente</w> que</w> vous</w> alli ez</w> à</w> nouveau</w> bien</w> .</w>'}\n",
      "{'source': '[CLS] he is as clever as any of his classmates . [SEP]', 'truth': \"il</w> est</w> aussi</w> intelli gent</w> que</w> n'</w> importe</w> lequel</w> de</w> ses</w> camarades</w> .</w>\", 'sampled': \"il</w> est</w> aussi</w> intelli gent</w> que</w> n'</w> importe</w> quelle</w> de</w> ses</w> fesses</w> .</w>\"}\n",
      "{'source': \"[CLS] you ' re still mad , are n ' t you ? [SEP]\", 'truth': \"tu</w> es</w> toujours</w> en</w> colère</w> ,</w> n'</w> est-ce</w> pas</w> ?</w>\", 'sampled': \"tu</w> es</w> toujours</w> en</w> colère</w> ,</w> n'</w> est-ce</w> pas</w> ?</w>\"}\n",
      "{'source': \"[CLS] i ' m going to do an internship at a local company . [SEP]\", 'truth': 'je</w> vais</w> faire</w> un</w> stage</w> dans</w> une</w> entreprise</w> locale</w> .</w>', 'sampled': 'je</w> vais</w> faire</w> un</w> ticket</w> dans</w> une</w> chambre</w> plusieurs</w> .</w>'}\n",
      "{'source': \"[CLS] i ' m sorry that i did n ' t email you sooner . [SEP]\", 'truth': \"je</w> suis</w> désolé</w> de</w> ne</w> pas</w> t'</w> avoir</w> envoyé</w> un</w> courriel</w> plus</w> tôt</w> .</w>\", 'sampled': \"je</w> suis</w> désolé</w> de</w> ne</w> pas</w> t'</w> avoir</w> envoyé</w> un</w> courriel</w> plus</w> tôt</w> .</w>\"}\n"
     ]
    }
   ],
   "source": [
    "for i in range(24):\n",
    "    print(get_all_sentences(eng_vocab,french_vocab, batch_dict, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0dfb53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
